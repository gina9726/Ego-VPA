
model:
    pretrain: ckpt/egtea.pt
    freeze_vis_backbone: true
    freeze_txt_backbone: true
    inflat_posemb: true
    num_frames: 16
    text_prompt:
        n_ctx: 8
        use_basis: true
    visual_prompt:
        num_layers: 12
        prompt_dim: 512
        num_tokens: 128
        deep: true
        deep_shared: false
        split_st: false
        pt_spt: true
        pt_tmp: false
        style: VoP_c_basis  # VoP_c: prompts are generated by context fusion; frame-specific attention
        n_seg: 16     # number of segments per video (n_seg=clip_length -> 1 frame/seg)
        K_s: 8        # boundary of intra-frame/inter-frame attention (VoP_f+c)
        basis:
            size: 10

data:
    dataset: egtea
    root: /data/EGTEA/cropped_clips
    metadata: /data/EGTEA/train_split1.txt
    metadata_val: /data/EGTEA/test_split1.txt
    clip_length: 16
    clip_stride: 2
    num_crops: 3
    num_clips: 10

training:
    lr: 0.01
    batch_size: 32 
    epoch: 10
    use_checkpoint: true
    save_freq: 10
    eval_freq: 1

